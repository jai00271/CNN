## Advanced Convolutions

*Dilated Convolution a.k.a Atrous Convolution*

Dilated convolutions helps us in increasing the receptive field without adding any parameters to our network. The key application the dilated convolution authors have in mind is dense prediction: vision applications where the predicted object that has similar size and structure to the input image. Dilated convolutions are used in Image segmentations, Audio generations, Machine translations, etc. In many such applications one wants to integrate information from different spatial scales and balance two properties:

1. local, pixel-level accuracy, such as precise detection of edges, and
2. integrating knowledge of the wider, global context

Simply putting,

**When l=1, it is standard convolution.**

**When l>1, it is dilated convolution.**


  ![alt text](https://cdn-images-1.medium.com/max/2000/0*oX5IPr7TlVM2NpEU.gif)

**Standard Convolution (l=1)**

![alt text](https://cdn-images-1.medium.com/max/2000/0*3cTXIemm0k3Sbask.gif)

**Dilated Convolution (l=2)**

We can see that **the receptive field is larger** compared with the standard one.

![alt text](https://cdn-images-1.medium.com/max/2000/1*tnDNIyPePgHvb8JIx8SbqA.png)

​                            (a)                                                            (b)                                              (c)

In above image we see that Systematic dilation supports exponential expansion of the receptive field without loss of
resolution or coverage. (a) F1 is produced from F0 by a 1-dilated convolution; each element in F1 has a receptive field of 3×3. (b) F2 is produced from F1 by a 2-dilated convolution; each element in F2 has a receptive field of 7×7. (c) F3 is produced from F2 by a 4-dilated convolution; each element in F3 has a receptive field of 15×15. The number of parameters associated with each layer is identical. The receptive field grows exponentially while the number of parameters grows linearly. easy to see that the size of the receptive field of each element in Fi+1 is (2i+2 − 1)×(2i+2 − 1).
The receptive field is a square of exponentially increasing size.

------

*DECONVOLUTION or Fractionally Strided OR Transpose Convolution*

The improvement of resolution of images or other data by a mathematical algorithm designed to separate the information from artefacts which result from the method of collecting it. Deconvolution layer is a very unfortunate name and should rather be called a transposed convolutional layer.

Visually, for a transposed convolution with stride one and no padding, we just pad the original input (blue entries) with zeroes (white entries) (Figure 1).

![alt text](https://i.stack.imgur.com/YyCu2.gif)

In case of stride two and padding, the transposed convolution would look like this (Figure 2):

![alt text](https://i.stack.imgur.com/f2RiP.gif)

You can find more (great) visualisations of convolutional arithmetics [here](https://github.com/vdumoulin/conv_arithmetic).

Now this introduces checker board issue. Lets understand what is checker board issue?

Checker Board Issue:

When we look very closely at images generated by neural networks, we often see a strange checkerboard pattern of artifacts. It’s more obvious in some cases than others, but a large fraction of recent models exhibit this behavior.

![alt text](http://distill.pub/2016/deconv-checkerboard/thumbnail.jpg)

Now if you notice above, you can see small checkboxes. This is checkerboard issue. 

![alt text](https://jie-tao.com/wp-content/uploads/2019/02/checkerboard-2.jpg)

------

*Spatial Separable Convolutions*

![alt text](https://cdn-images-1.medium.com/max/2000/1*o3mKhG3nHS-1dWa_plCeFw.png)

In this convolution instead of operating with 3x3 kernel over input image, we first convolve with 3x1 kernel and after getting intermediate result we again convolve with 1x3 kernel. Now by doing spatial separable convolutions we are only performing 6 multiplications instead of 9. 

Disadvantage:

The main issue with the spatial separable convolution is that not all kernels can be “separated” into two, smaller kernels. This becomes particularly bothersome during training, since of all the possible kernels the network could have adopted, it can only end up using one of the tiny portion that can be separated into two smaller kernels.

------

*Depthwise Separable Convolution*

Depthwise Separable Convolution is used to reduce the model size and complexity. It is particularly useful for mobile and embedded vision applications.

- Smaller model size: Fewer number of parameters
- Smaller complexity: Fewer Multiplications and Additions (Multi-Adds)

But before jumping to Depthwise Separable Convolution, lets understand how Normal and Depthwise convolutions works.

![Normal Convolution](https://cdn-images-1.medium.com/max/2000/1*fgYepSWdgywsqorf3bdksg.png)

​	                                                                        Normal convolution

Above is an example of normal convolution where our filter size is 5x5x3(height x length x channel) which is convolving on 12 x 12 x 3 image(height x width x channel) giving us a result of 8x8x1. This means our result is 1 image of 8X8 size and containing 1 channel. Now you might be thinking why are we reducing it to 1 channel, what if I want more channels.

![alt text](https://cdn-images-1.medium.com/max/2000/1*XloAmCh5bwE4j1G7yk5THw.png)

​                                                      Normal convolution with 8x8x256 output

Well, we can create 256 kernels to create 256 8x8x1 images, then stack them up together to create a 8x8x256 image output.

*Depth Wise Convolution*

![alt text](https://cdn-images-1.medium.com/max/2000/1*Esdvt3HLoEQFen94x29Z0A.png)

Now in depth wise convolution, Filters and image have been broken into three different channels and then convolved separately and stacked thereafter. See above, we have 3 channel filter and 3 channel image. What we do is — break the filter and image into three different channels and then convolve the corresponding image with corresponding channel and then stack them back. Although parameters are remaining same, this convolution gives you three output channels with only one 3-channel filter while, you would require three 3-channel filters if you would use normal convolution.

Now lets read about Depth wise separable convolutions.

![alt text](https://cdn-images-1.medium.com/max/2000/1*Voah8cvrs7gnTDf6acRvDw.png)

Now you can say that Depthwise separable convolutions = Depthwise convolutions + Pointwise Convolutions

1. **Depthwise convolution** is the **channel-wise DK×DK spatial convolution**. Suppose in the figure above, we have 5 channels, then we will have 5 DK×DK spatial convolution.
2. **Pointwise convolution** actually is the **1×1 convolution** to change the dimension.

------





# 





Reference:

[Dilated Convo White paper](https://arxiv.org/pdf/1511.07122.pdf)

[DECONVOLUTION or Fractionally Strided OR Transpose Convolution](https://datascience.stackexchange.com/a/12110/74860)

[Checker Board Issue](https://distill.pub/2016/deconv-checkerboard/)

[Depthwise-Separable-Convolution](<https://towardsdatascience.com/review-mobilenetv1-depthwise-separable-convolution-light-weight-model-a382df364b69>)

